{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a8334-c140-4a8d-af69-d76db1e2f8e5",
   "metadata": {
    "id": "475a8334-c140-4a8d-af69-d76db1e2f8e5"
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eedc6dc-aa97-4bc6-847c-f0629fb2ec31",
   "metadata": {
    "id": "5eedc6dc-aa97-4bc6-847c-f0629fb2ec31",
    "outputId": "a44f82ea-3d6c-4222-a2eb-4385df6680eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca711401-a91d-4779-bff1-fd8531fa14b8",
   "metadata": {
    "id": "ca711401-a91d-4779-bff1-fd8531fa14b8"
   },
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10cee66-7b15-4cea-9d2d-abb5a4f71ef8",
   "metadata": {
    "id": "b10cee66-7b15-4cea-9d2d-abb5a4f71ef8"
   },
   "outputs": [],
   "source": [
    "def msg2dict(msg):\n",
    "    result = dict()\n",
    "    if 'note_on' in msg:\n",
    "        on_ = True\n",
    "    elif 'note_off' in msg:\n",
    "        on_ = False\n",
    "    else:\n",
    "        on_ = None\n",
    "    result['time'] = int(msg[msg.rfind('time'):].split(' ')[0].split('=')[1].translate(\n",
    "        str.maketrans({a: None for a in string.punctuation})))\n",
    "\n",
    "    if on_ is not None:\n",
    "        for k in ['note', 'velocity']:\n",
    "            result[k] = int(msg[msg.rfind(k):].split(' ')[0].split('=')[1].translate(\n",
    "                str.maketrans({a: None for a in string.punctuation})))\n",
    "    return [result, on_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10392a4-6eda-44bd-b539-c918530f8dca",
   "metadata": {
    "id": "c10392a4-6eda-44bd-b539-c918530f8dca"
   },
   "outputs": [],
   "source": [
    "def switch_note(last_state, note, velocity, on_=True):\n",
    "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of this range will be ignored\n",
    "    result = [0] * 88 if last_state is None else last_state.copy()\n",
    "    if 21 <= note <= 108:\n",
    "        result[note-21] = velocity if on_ else 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb56093-259d-4a12-86a9-ce97c3c2f86c",
   "metadata": {
    "id": "1bb56093-259d-4a12-86a9-ce97c3c2f86c"
   },
   "outputs": [],
   "source": [
    "def get_new_state(new_msg, last_state):\n",
    "    new_msg, on_ = msg2dict(str(new_msg))\n",
    "    new_state = switch_note(last_state, note=new_msg['note'], velocity=new_msg['velocity'], on_=on_) if on_ is not None else last_state\n",
    "    return [new_state, new_msg['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1bf3de-3f60-41ec-b812-d334fcd2970d",
   "metadata": {
    "id": "6b1bf3de-3f60-41ec-b812-d334fcd2970d"
   },
   "outputs": [],
   "source": [
    "def track2seq(track):\n",
    "    result = []\n",
    "    last_state, last_time = get_new_state(str(track[0]), [0]*88)\n",
    "    for i in range(1, len(track)):\n",
    "        new_state, new_time = get_new_state(track[i], last_state)\n",
    "        if new_time > 0:\n",
    "            result += [last_state]*new_time\n",
    "        last_state, last_time = new_state, new_time\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad86a17-e3c8-49e5-907c-792decf4fb24",
   "metadata": {
    "id": "1ad86a17-e3c8-49e5-907c-792decf4fb24"
   },
   "outputs": [],
   "source": [
    "def mid2arry(mid, min_msg_pct=0.1):\n",
    "    tracks_len = [len(tr) for tr in mid.tracks]\n",
    "    min_n_msg = max(tracks_len) * min_msg_pct\n",
    "    # convert each track to nested list\n",
    "    all_arys = []\n",
    "    for i in range(len(mid.tracks)):\n",
    "        if len(mid.tracks[i]) > min_n_msg:\n",
    "            ary_i = track2seq(mid.tracks[i])\n",
    "            all_arys.append(ary_i)\n",
    "    # make all nested list the same length\n",
    "    max_len = max([len(ary) for ary in all_arys])\n",
    "    for i in range(len(all_arys)):\n",
    "        if len(all_arys[i]) < max_len:\n",
    "            all_arys[i] += [[0] * 88] * (max_len - len(all_arys[i]))\n",
    "    all_arys = np.array(all_arys)\n",
    "    all_arys = all_arys.max(axis=0)\n",
    "    # trim: remove consecutive 0s in the beginning and at the end\n",
    "    sums = all_arys.sum(axis=1)\n",
    "    ends = np.where(sums > 0)[0]\n",
    "    return all_arys[min(ends): max(ends)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af352c-b1ea-415c-9c8f-1d3a0334563c",
   "metadata": {
    "id": "e0af352c-b1ea-415c-9c8f-1d3a0334563c"
   },
   "outputs": [],
   "source": [
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, midi_dir, max_files=30000):\n",
    "        self.file_paths = [os.path.join(midi_dir, f) for f in os.listdir(midi_dir) if f.endswith('.mid')]\n",
    "        random.shuffle(self.file_paths)\n",
    "        self.file_paths = self.file_paths[:max_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        for _ in range(10):  # Try up to 10 times before giving up\n",
    "            path = self.file_paths[idx]\n",
    "            try:\n",
    "                mid = mido.MidiFile(path)\n",
    "                arr = mid2arry(mid)\n",
    "\n",
    "                if arr is None or len(arr) < 6000:\n",
    "                    #print(f\"Skipping (too short or silent): {path}\")\n",
    "                    idx = (idx + 1) % len(self.file_paths)\n",
    "                    continue\n",
    "\n",
    "                arr = arr[:8000]  # Cap at 8000 rows\n",
    "                arr = np.array(arr, dtype=np.float32)\n",
    "                arr /= 127.0\n",
    "                tensor = torch.from_numpy(arr).clone()\n",
    "                del arr\n",
    "                gc.collect()\n",
    "                return tensor\n",
    "\n",
    "            except Exception as e:\n",
    "                #print(f\"Failed at {path}: {e}\")\n",
    "                idx = (idx + 1) % len(self.file_paths)\n",
    "\n",
    "        # If it fails 10 times in a row, just return a zero tensor\n",
    "        print(\"Too many failures. Returning dummy tensor.\")\n",
    "        return torch.zeros((8000, 88), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7130ae0f-d33e-4788-b63d-8afaae9364b2",
   "metadata": {
    "id": "7130ae0f-d33e-4788-b63d-8afaae9364b2"
   },
   "outputs": [],
   "source": [
    "def midi_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pads each sample in the batch to exactly 8000 rows (sequence length).\n",
    "    \"\"\"\n",
    "    target_len = 8000\n",
    "    processed_batch = []\n",
    "\n",
    "    for x in batch:\n",
    "        length = x.size(0)\n",
    "        if length < target_len:\n",
    "            pad_len = target_len - length\n",
    "            padding = torch.zeros((pad_len, x.size(1)))\n",
    "            x_padded = torch.cat([x, padding], dim=0)\n",
    "        else:\n",
    "            x_padded = x[:target_len]\n",
    "        processed_batch.append(x_padded)\n",
    "\n",
    "    return torch.stack(processed_batch)  # Shape: (batch_size, 8000, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115acfe-08d6-409f-a6bd-387fe764db9c",
   "metadata": {
    "id": "c115acfe-08d6-409f-a6bd-387fe764db9c"
   },
   "outputs": [],
   "source": [
    "dataset = MIDIDataset(midi_dir=\"/home/sakshisahemail/Desktop/GANs/Dataset/Full_Dataset/\", max_files=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d193bb-5df9-4fd4-9349-c959a230173c",
   "metadata": {
    "id": "49d193bb-5df9-4fd4-9349-c959a230173c",
    "outputId": "83fad6a9-ef00-4c51-85b1-2656c9a4cd88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MIDI files found: 30000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total MIDI files found: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d1a1c-07b2-4ca9-a875-8895ff55c345",
   "metadata": {
    "id": "0f2d1a1c-07b2-4ca9-a875-8895ff55c345",
    "outputId": "c08efc23-7e22-4845-e580-3a6f556223bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "num_workers = max(1, multiprocessing.cpu_count() - 1)\n",
    "num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64a495-cca0-4c29-90c9-c4fbff6ca2fb",
   "metadata": {
    "id": "cf64a495-cca0-4c29-90c9-c4fbff6ca2fb"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=midi_collate_fn,\n",
    "    num_workers=num_workers, \n",
    "    pin_memory=True,    \n",
    "    drop_last=True     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5492c-cbb5-452a-8062-11141e62de7f",
   "metadata": {
    "id": "21a5492c-cbb5-452a-8062-11141e62de7f"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Starting from latent vector\n",
    "            nn.Linear(latent_dim, 256 * 500 * 11),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (256, 500, 11)),  # Shape: (256, 500, 11)\n",
    "\n",
    "            # Upsample to (128, 1000, 22)\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Upsample to (64, 2000, 22) — only height increases\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(4, 3), stride=(2, 1), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Upsample to (32, 4000, 44)\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Final upsample to (1, 8000, 88)\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cf8a0-a55a-4aa4-9b89-b59dab636e92",
   "metadata": {
    "id": "4d0cf8a0-a55a-4aa4-9b89-b59dab636e92"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4, stride=4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, 8000, 88)\n",
    "            out = self.features(dummy_input)\n",
    "            flattened_size = out.view(1, -1).size(1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a39878-1f9d-4e4d-b34b-25ccabd0cfbd",
   "metadata": {
    "id": "b7a39878-1f9d-4e4d-b34b-25ccabd0cfbd"
   },
   "outputs": [],
   "source": [
    "mean = 0.0\n",
    "std = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c82f39-c13b-4f7e-8749-64e6529f3292",
   "metadata": {
    "id": "a0c82f39-c13b-4f7e-8749-64e6529f3292"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90cf05a-377d-4780-90f3-b1116c33667c",
   "metadata": {
    "id": "d90cf05a-377d-4780-90f3-b1116c33667c"
   },
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n",
    "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = torch.ones(d_interpolates.size(), device=device)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) + 1e-8 - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ded9e-13ca-49b3-85fe-de495ce75d5d",
   "metadata": {
    "id": "306ded9e-13ca-49b3-85fe-de495ce75d5d",
    "outputId": "75f0a075-f862-420e-9765-1c91e61adbfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=128000, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_dim = 100  # Latent vector dimension for generator\n",
    "G = Generator(z_dim)\n",
    "D = Discriminator()\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc353f-761b-437f-99bf-de6270d506d5",
   "metadata": {
    "id": "8fbc353f-761b-437f-99bf-de6270d506d5",
    "outputId": "97dde82d-51a7-431b-d1bb-2e40fbb8096c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909232d-e516-4a52-91b4-d91618bf210d",
   "metadata": {
    "id": "9909232d-e516-4a52-91b4-d91618bf210d",
    "outputId": "bfe49c4f-6bb8-4d0a-a0f3-0ed5a708b697"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=1408000, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Unflatten(dim=1, unflattened_size=(256, 500, 11))\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 3), stride=(2, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c96023-79a1-444b-84a3-8fdc2e5a0b22",
   "metadata": {
    "id": "59c96023-79a1-444b-84a3-8fdc2e5a0b22",
    "outputId": "3803bf49-b143-4f62-cef4-feafafd8c6d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=128000, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236e4b4-5aee-470b-b238-09bb9c26f178",
   "metadata": {
    "id": "a236e4b4-5aee-470b-b238-09bb9c26f178"
   },
   "outputs": [],
   "source": [
    "latent_dim = z_dim\n",
    "lr_G = 0.0001\n",
    "lr_D = 0.00005\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=lr_D, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ef52c-1dff-47df-8046-5e67a410ee3b",
   "metadata": {
    "id": "7f1ef52c-1dff-47df-8046-5e67a410ee3b"
   },
   "outputs": [],
   "source": [
    "lambda_gp = 10\n",
    "n_critic = 5\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f42500-cd2e-45a4-8b56-2a8e0e0c63c6",
   "metadata": {
    "id": "d4f42500-cd2e-45a4-8b56-2a8e0e0c63c6",
    "outputId": "61914baf-71b9-4add-b218-193006002fc5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                          | 0/937 [00:00<?, ?it/s]/root/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 1 | Avg Loss D: -591.5999 | Avg Loss G: -1510.0460\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 2 | Avg Loss D: -170.1729 | Avg Loss G: -271.3940\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 3 | Avg Loss D: -119.2517 | Avg Loss G: -11.2613\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 4 | Avg Loss D: -47.9646 | Avg Loss G: -22.8571\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 5 | Avg Loss D: -35.2043 | Avg Loss G: 0.3676\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 6 | Avg Loss D: -30.9095 | Avg Loss G: 6.0554\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 7 | Avg Loss D: -27.8434 | Avg Loss G: 0.9519\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 8 | Avg Loss D: -25.9520 | Avg Loss G: 1.3571\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 9 | Avg Loss D: -24.6375 | Avg Loss G: -7.2292\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 10 | Avg Loss D: -23.2596 | Avg Loss G: -23.9502\n",
      "\n",
      "Epoch 11/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 11 | Avg Loss D: -22.5672 | Avg Loss G: -38.7396\n",
      "\n",
      "Epoch 12/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 12 | Avg Loss D: -21.3228 | Avg Loss G: -42.3104\n",
      "\n",
      "Epoch 13/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 13 | Avg Loss D: -20.4848 | Avg Loss G: -49.6574\n",
      "\n",
      "Epoch 14/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 14 | Avg Loss D: -20.0593 | Avg Loss G: -56.8813\n",
      "\n",
      "Epoch 15/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 15 | Avg Loss D: -19.4485 | Avg Loss G: -67.2189\n",
      "\n",
      "Epoch 16/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 16 | Avg Loss D: -19.0795 | Avg Loss G: -74.1820\n",
      "\n",
      "Epoch 17/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 17 | Avg Loss D: -18.9488 | Avg Loss G: -80.0631\n",
      "\n",
      "Epoch 18/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 18 | Avg Loss D: -18.5834 | Avg Loss G: -87.7245\n",
      "\n",
      "Epoch 19/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 19 | Avg Loss D: -18.4222 | Avg Loss G: -92.7662\n",
      "\n",
      "Epoch 20/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 20 | Avg Loss D: -18.4916 | Avg Loss G: -97.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "G.train()\n",
    "D.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/10\")\n",
    "\n",
    "    epoch_loss_D = 0.0\n",
    "    epoch_loss_G = 0.0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "    for batch_idx, real_imgs in progress_bar:\n",
    "        real_imgs = real_imgs.to(device).unsqueeze(1)\n",
    "        b_size = real_imgs.size(0)\n",
    "\n",
    "        # === Train Discriminator ===\n",
    "        for _ in range(n_critic):\n",
    "            z = torch.randn(b_size, latent_dim, device=device)\n",
    "            fake_imgs = G(z)\n",
    "\n",
    "            D_real = D(real_imgs)\n",
    "            D_fake = D(fake_imgs.detach())\n",
    "\n",
    "            gradient_penalty = compute_gradient_penalty(D, real_imgs, fake_imgs.detach())\n",
    "\n",
    "            loss_D = -torch.mean(D_real) + torch.mean(D_fake) + lambda_gp * gradient_penalty\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        z = torch.randn(b_size, latent_dim, device=device)\n",
    "        fake_imgs = G(z)\n",
    "        D_fake = D(fake_imgs)\n",
    "\n",
    "        loss_G = -torch.mean(D_fake)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        epoch_loss_D += loss_D.item()\n",
    "        epoch_loss_G += loss_G.item()\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss D': f\"{loss_D.item():.4f}\",\n",
    "            'Loss G': f\"{loss_G.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    avg_loss_D = epoch_loss_D / len(dataloader)\n",
    "    avg_loss_G = epoch_loss_G / len(dataloader)\n",
    "    print(f\"✅ Epoch {epoch+1} | Avg Loss D: {avg_loss_D:.4f} | Avg Loss G: {avg_loss_G:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11f18f-efe0-4a96-ae9f-043a24ddf03c",
   "metadata": {
    "id": "bc11f18f-efe0-4a96-ae9f-043a24ddf03c"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_samples(generator, num_samples=500, output_dir=\"generated_samples_wgangp\", batch_size=1):\n",
    "    import gc\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    generator.eval()\n",
    "\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "    sample_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(num_batches):\n",
    "            current_batch_size = min(batch_size, num_samples - sample_count)\n",
    "            z = torch.randn(current_batch_size, latent_dim, device=device)\n",
    "            fake_imgs = generator(z)\n",
    "\n",
    "            fake_imgs = fake_imgs.squeeze(1).cpu().numpy()\n",
    "            for i, img in enumerate(fake_imgs):\n",
    "                np.save(os.path.join(output_dir, f\"generated_sample_{sample_count + 1}.npy\"), img)\n",
    "                sample_count += 1\n",
    "\n",
    "            # Memory cleanup\n",
    "            del z, fake_imgs\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    print(f\"Generated {num_samples} samples and saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631588ba-d482-4188-bd40-4b391c15fe81",
   "metadata": {
    "id": "631588ba-d482-4188-bd40-4b391c15fe81",
    "outputId": "62f12e7f-661a-4982-b7f2-c8ffa4bf2ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 samples and saved to generated_samples_wgangp\n"
     ]
    }
   ],
   "source": [
    "generate_and_save_samples(G, num_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b061087a-6144-4591-bc02-efdb6406045d",
   "metadata": {
    "id": "b061087a-6144-4591-bc02-efdb6406045d"
   },
   "outputs": [],
   "source": [
    "def save_model_and_optimizer_generator(model, optimizer, epoch, model_dir=\"model_checkpoints_wgangp\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, f\"generator_epoch_{epoch+1}.pth\")\n",
    "    optimizer_path = os.path.join(model_dir, f\"generator_optimizer_epoch_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "    print(f\"Generator model and optimizer states saved after epoch {epoch+1}\")\n",
    "\n",
    "def save_model_and_optimizer_discriminator(model, optimizer, epoch, model_dir=\"model_checkpoints_wgangp\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, f\"discriminator_epoch_{epoch+1}.pth\")\n",
    "    optimizer_path = os.path.join(model_dir, f\"discriminator_optimizer_epoch_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "    print(f\"Discriminator model and optimizer states saved after epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1d4dd-acba-477e-92dd-904ecdf9b489",
   "metadata": {
    "id": "c6b1d4dd-acba-477e-92dd-904ecdf9b489",
    "outputId": "110506f1-ffbf-499f-d58d-d85baf563bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator model and optimizer states saved after epoch 20\n",
      "Discriminator model and optimizer states saved after epoch 20\n"
     ]
    }
   ],
   "source": [
    "save_model_and_optimizer_generator(G, optimizer_G, epoch)\n",
    "save_model_and_optimizer_discriminator(D, optimizer_D, epoch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
