{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c70696-31fe-4362-acc1-d7ddf473c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6809d777-7db3-4974-ae1b-592dbc976d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e85a06-8ad3-4be7-936b-315ff7a09c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg2dict(msg):\n",
    "    result = dict()\n",
    "    if 'note_on' in msg:\n",
    "        on_ = True\n",
    "    elif 'note_off' in msg:\n",
    "        on_ = False\n",
    "    else:\n",
    "        on_ = None\n",
    "    result['time'] = int(msg[msg.rfind('time'):].split(' ')[0].split('=')[1].translate(\n",
    "        str.maketrans({a: None for a in string.punctuation})))\n",
    "\n",
    "    if on_ is not None:\n",
    "        for k in ['note', 'velocity']:\n",
    "            result[k] = int(msg[msg.rfind(k):].split(' ')[0].split('=')[1].translate(\n",
    "                str.maketrans({a: None for a in string.punctuation})))\n",
    "    return [result, on_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836886aa-d288-40da-940a-46deb42939a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_note(last_state, note, velocity, on_=True):\n",
    "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of this range will be ignored\n",
    "    result = [0] * 88 if last_state is None else last_state.copy()\n",
    "    if 21 <= note <= 108:\n",
    "        result[note-21] = velocity if on_ else 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c319c44-e9c1-4412-8256-976469c970d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state(new_msg, last_state):\n",
    "    new_msg, on_ = msg2dict(str(new_msg))\n",
    "    new_state = switch_note(last_state, note=new_msg['note'], velocity=new_msg['velocity'], on_=on_) if on_ is not None else last_state\n",
    "    return [new_state, new_msg['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd1293bc-5bc4-41dc-bc2a-ece696bfd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track2seq(track):\n",
    "    result = []\n",
    "    last_state, last_time = get_new_state(str(track[0]), [0]*88)\n",
    "    for i in range(1, len(track)):\n",
    "        new_state, new_time = get_new_state(track[i], last_state)\n",
    "        if new_time > 0:\n",
    "            result += [last_state]*new_time\n",
    "        last_state, last_time = new_state, new_time\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d21230a3-f706-482d-9988-89f72eba9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mid2arry(mid, min_msg_pct=0.1):\n",
    "    tracks_len = [len(tr) for tr in mid.tracks]\n",
    "    min_n_msg = max(tracks_len) * min_msg_pct\n",
    "    # convert each track to nested list\n",
    "    all_arys = []\n",
    "    for i in range(len(mid.tracks)):\n",
    "        if len(mid.tracks[i]) > min_n_msg:\n",
    "            ary_i = track2seq(mid.tracks[i])\n",
    "            all_arys.append(ary_i)\n",
    "    # make all nested list the same length\n",
    "    max_len = max([len(ary) for ary in all_arys])\n",
    "    for i in range(len(all_arys)):\n",
    "        if len(all_arys[i]) < max_len:\n",
    "            all_arys[i] += [[0] * 88] * (max_len - len(all_arys[i]))\n",
    "    all_arys = np.array(all_arys)\n",
    "    all_arys = all_arys.max(axis=0)\n",
    "    # trim: remove consecutive 0s in the beginning and at the end\n",
    "    sums = all_arys.sum(axis=1)\n",
    "    ends = np.where(sums > 0)[0]\n",
    "    return all_arys[min(ends): max(ends)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f94e8e-fb14-4dcb-b951-fbc3c0820fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, midi_dir, max_files=30000):\n",
    "        self.file_paths = [os.path.join(midi_dir, f) for f in os.listdir(midi_dir) if f.endswith('.mid')]\n",
    "        random.shuffle(self.file_paths)\n",
    "        self.file_paths = self.file_paths[:max_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        for _ in range(10):  # Try up to 10 times before giving up\n",
    "            path = self.file_paths[idx]\n",
    "            try:\n",
    "                mid = mido.MidiFile(path)\n",
    "                arr = mid2arry(mid)\n",
    "\n",
    "                if arr is None or len(arr) < 4000:\n",
    "                    #print(f\"Skipping (too short or silent): {path}\")\n",
    "                    idx = (idx + 1) % len(self.file_paths)\n",
    "                    continue\n",
    "\n",
    "                arr = arr[:8000]  # Cap at 8000 rows\n",
    "                arr = np.array(arr, dtype=np.float32)\n",
    "                arr /= 127.0\n",
    "                tensor = torch.from_numpy(arr).clone()\n",
    "                del arr\n",
    "                gc.collect()\n",
    "                return tensor\n",
    "\n",
    "            except Exception as e:\n",
    "                #print(f\"Failed at {path}: {e}\")\n",
    "                idx = (idx + 1) % len(self.file_paths)\n",
    "\n",
    "        # if it fails 10 times in a row, just return a zero tensor\n",
    "        print(\"Too many failures. Returning dummy tensor.\")\n",
    "        return torch.zeros((8000, 88), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab5c574-8d79-4a6e-8bbd-6a85425ed1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pads each sample in the batch to exactly 8000 rows (sequence length).\n",
    "    \"\"\"\n",
    "    target_len = 8000\n",
    "    processed_batch = []\n",
    "\n",
    "    for x in batch:\n",
    "        length = x.size(0)\n",
    "        if length < target_len:\n",
    "            pad_len = target_len - length\n",
    "            padding = torch.zeros((pad_len, x.size(1)))\n",
    "            x_padded = torch.cat([x, padding], dim=0)\n",
    "        else:\n",
    "            x_padded = x[:target_len]\n",
    "        processed_batch.append(x_padded)\n",
    "\n",
    "    return torch.stack(processed_batch)  # Shape: (batch_size, 8000, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9989bbe4-ff22-4472-9ab0-299427c63e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MIDIDataset(midi_dir=\"/home/sakshisahemail/Desktop/GANs/Dataset/Full_Dataset/\", max_files=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dcc9e24-20ca-49b1-9e02-fa714329926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MIDI files found: 30000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total MIDI files found: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "565dbffe-1495-4eb1-8a58-73bd7aae3c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "num_workers = max(1, multiprocessing.cpu_count() - 1)\n",
    "num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3702f4c-bdf7-4c9c-85ef-c3a5605d1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=midi_collate_fn,\n",
    "    num_workers=num_workers,  \n",
    "    pin_memory=True,    \n",
    "    drop_last=True      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11f7aee3-efaa-48b3-a886-b0ec3fd06326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Starting from latent vector\n",
    "            nn.Linear(latent_dim, 256 * 500 * 11),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (256, 500, 11)),  # Shape: (256, 500, 11)\n",
    "\n",
    "            # Upsample to (128, 1000, 22)\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Upsample to (64, 2000, 22) â€” only height increases\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(4, 3), stride=(2, 1), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Upsample to (32, 4000, 44)\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Final upsample to (1, 8000, 88)\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84738048-c0c7-443d-a734-57f58f766bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4, stride=4),      # [B, 64, 2000, 22]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=4),    # [B, 128, 500, 5]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # [B, 256, ~250, ~3]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),  # [B, 512, ~125, ~2]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        # Flatten size calculation\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, 8000, 88)\n",
    "            out = self.features(dummy_input)\n",
    "            flattened_size = out.view(1, -1).size(1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c69348e2-08c1-462a-8201-354cb526232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.0\n",
    "std = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44e18976-76d7-48e1-89fa-28939ebcad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097ddd89-ef12-40aa-b85e-dc38c4ffa691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=128000, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_dim = 100  # Latent vector dimension for generator\n",
    "G = Generator(z_dim)\n",
    "D = Discriminator()\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c3f2669-cb7c-4c9a-b5ee-8f360e870432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e9ba743-1f2c-4c8a-a8b8-6d6571b9ae67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=1408000, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Unflatten(dim=1, unflattened_size=(256, 500, 11))\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 3), stride=(2, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5837a938-20c7-4857-9184-33861f05421b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=128000, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4213dac0-28d7-41db-85bc-b9c44644c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = z_dim\n",
    "lr = 0.0002\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=4e-4, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d3090e5-a499-49c6-a21f-1f82e265866c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1/10 | Avg Loss D: 1.1138 | Avg Loss G: 18.3362\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2/10 | Avg Loss D: 0.6222 | Avg Loss G: 10.2557\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3/10 | Avg Loss D: 0.8563 | Avg Loss G: 12.1324\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 4/10 | Avg Loss D: 0.6074 | Avg Loss G: 11.4468\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 5/10 | Avg Loss D: 0.5541 | Avg Loss G: 12.0146\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 6/10 | Avg Loss D: 0.5152 | Avg Loss G: 10.1286\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 7/10 | Avg Loss D: 0.4650 | Avg Loss G: 10.9475\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 8/10 | Avg Loss D: 0.4189 | Avg Loss G: 10.2500\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 9/10 | Avg Loss D: 0.4120 | Avg Loss G: 9.6316\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 10/10 | Avg Loss D: 0.4062 | Avg Loss G: 9.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "G.train()\n",
    "D.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"\\nEpoch {epoch+1}/{10}\")\n",
    "    \n",
    "    epoch_loss_D = 0.0\n",
    "    epoch_loss_G = 0.0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "    for batch_idx, real_imgs in progress_bar:\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        real_imgs = real_imgs.unsqueeze(1)\n",
    "        b_size = real_imgs.size(0)\n",
    "\n",
    "        # === Train Discriminator ===\n",
    "        z = torch.randn(b_size, latent_dim, device=device)\n",
    "        fake_imgs = G(z)\n",
    "\n",
    "        D_real = D(real_imgs).view(-1)\n",
    "        D_fake = D(fake_imgs.detach()).view(-1)\n",
    "\n",
    "        real_labels = torch.full_like(D_real, 0.9, device=device)  # label smoothing\n",
    "        fake_labels = torch.zeros_like(D_fake, device=device)\n",
    "\n",
    "        loss_D_real = criterion(D_real, real_labels)\n",
    "        loss_D_fake = criterion(D_fake, fake_labels)\n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        D_fake = D(fake_imgs).view(-1)\n",
    "        real_gen_labels = torch.ones_like(D_fake, device=device)\n",
    "        loss_G = criterion(D_fake, real_gen_labels)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        epoch_loss_D += loss_D.item()\n",
    "        epoch_loss_G += loss_G.item()\n",
    "\n",
    "        # Update tqdm bar with loss info\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss D': f\"{loss_D.item():.4f}\",\n",
    "            'Loss G': f\"{loss_G.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    avg_loss_D = epoch_loss_D / len(dataloader)\n",
    "    avg_loss_G = epoch_loss_G / len(dataloader)\n",
    "    print(f\"âœ… Epoch {epoch+1}/{10} | Avg Loss D: {avg_loss_D:.4f} | Avg Loss G: {avg_loss_G:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83eebff0-5bc7-4ff3-82d7-5050c60c1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"generated_samples\"\n",
    "model_dir = \"model_checkpoints\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "995c438b-35b0-4c9d-8ce2-5d2edec5a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_samples(generator, num_samples=500, output_dir=\"generated_samples\", batch_size=1):\n",
    "    import gc\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    generator.eval()\n",
    "\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "    sample_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(num_batches):\n",
    "            current_batch_size = min(batch_size, num_samples - sample_count)\n",
    "            z = torch.randn(current_batch_size, latent_dim, device=device)\n",
    "            fake_imgs = generator(z)\n",
    "\n",
    "            fake_imgs = fake_imgs.squeeze(1).cpu().numpy()\n",
    "            for i, img in enumerate(fake_imgs):\n",
    "                np.save(os.path.join(output_dir, f\"generated_sample_{sample_count + 1}.npy\"), img)\n",
    "                sample_count += 1\n",
    "\n",
    "            # Memory cleanup\n",
    "            del z, fake_imgs\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    print(f\"Generated {num_samples} samples and saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5745dfbb-2c47-47ab-96e4-2b53eacfd3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_optimizer_generator(model, optimizer, epoch, model_dir=\"model_checkpoints_1\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, f\"generator_epoch_{epoch+1}.pth\")\n",
    "    optimizer_path = os.path.join(model_dir, f\"generator_optimizer_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "\n",
    "    print(f\"Generator model and optimizer states saved after epoch {epoch+1}\")\n",
    "\n",
    "def save_model_and_optimizer_discriminator(model, optimizer, epoch, model_dir=\"model_checkpoints_1\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, f\"discriminator_epoch_{epoch+1}.pth\")\n",
    "    optimizer_path = os.path.join(model_dir, f\"discriminator_optimizer_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "\n",
    "    print(f\"Discriminator model and optimizer states saved after epoch {epoch+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99cb8941-3d77-447f-adef-4f23b1a13310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 samples and saved to generated_samples\n"
     ]
    }
   ],
   "source": [
    "generate_and_save_samples(G, num_samples=500, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14e4edc3-ffa0-4c62-a43a-1011283dae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator model and optimizer states saved after epoch 10\n",
      "Discriminator model and optimizer states saved after epoch 10\n"
     ]
    }
   ],
   "source": [
    "save_model_and_optimizer_generator(G, optimizer_G, epoch)\n",
    "save_model_and_optimizer_discriminator(D, optimizer_D, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
